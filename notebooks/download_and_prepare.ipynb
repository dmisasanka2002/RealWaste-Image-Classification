{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7dfc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Downloads RealWaste dataset (GitHub mirror) into data/RealWaste if not present.\n",
    "- Resizes images to IMG_SIZE x IMG_SIZE (global setting).\n",
    "- Normalizes pixel values to [0,1].\n",
    "- Creates stratified train/validation/test splits (70/15/15).\n",
    "- Computes class weights to mitigate imbalance.\n",
    "- Saves prepared arrays to data/realwaste_prepared.npz.\n",
    "- Writes a small sample gallery to outputs/sample_images.png.\n",
    "\n",
    "Edit the top variables to change dataset path or image size.\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------\n",
    "# User-editable globals\n",
    "# -------------------------\n",
    "IMG_SIZE = 128         # image size (128x128)\n",
    "BATCH_SIZE = 32        # global batch size (this is used here for caching plan; real use in training)\n",
    "DATA_DIR = \"../data\"      # root data folder\n",
    "RAW_DIR = f\"{DATA_DIR}\"   # where the raw dataset will be downloaded/extracted\n",
    "OUT_PREPARED = f\"{DATA_DIR}/realwaste_prepared.npz\"\n",
    "GITHUB_ZIP_URL = \"https://github.com/sam-single/realwaste/archive/refs/heads/master.zip\"\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40a4a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6730a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper: download file\n",
    "def download_file(url, out_path):\n",
    "    import requests\n",
    "    if os.path.exists(out_path):\n",
    "        print(\"Found existing:\", out_path)\n",
    "        return out_path\n",
    "    print(\"Downloading:\", url)\n",
    "    r = requests.get(url, stream=True)\n",
    "    r.raise_for_status()\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(\"Downloaded to:\", out_path)\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a8e01c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_members(zip_path, member_prefix, extract_to):\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        members = [m for m in z.namelist() if m.startswith(member_prefix)]\n",
    "        z.extractall(path=extract_to, members=members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "771ff31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dataset_downloaded():\n",
    "    \"\"\"\n",
    "    Download and extract the GitHub mirror of RealWaste into RAW_DIR.\n",
    "    The repo contains a folder with images in subfolders per class.\n",
    "    \"\"\"\n",
    "    if os.path.exists(RAW_DIR) and any(os.scandir(RAW_DIR)):\n",
    "        print(\"Raw dataset already present in\", RAW_DIR)\n",
    "        return\n",
    "\n",
    "    tmp_zip = \"data/realwaste_master.zip\"\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    download_file(GITHUB_ZIP_URL, tmp_zip)\n",
    "\n",
    "    print(\"Extracting archive...\")\n",
    "    with zipfile.ZipFile(tmp_zip, 'r') as z:\n",
    "        # extract entire archive and then move the inner folder to RAW_DIR\n",
    "        z.extractall(\"data\")\n",
    "    # the archive typically extracts to data/realwaste-master or similar; detect it\n",
    "    extracted_dirs = [d for d in Path(\"data\").iterdir() if d.is_dir() and d.name.startswith(\"realwaste\")]\n",
    "    if not extracted_dirs:\n",
    "        raise RuntimeError(\"Could not find extracted realwaste directory.\")\n",
    "    extracted_root = extracted_dirs[0]\n",
    "    # Move contents to RAW_DIR\n",
    "    if os.path.exists(RAW_DIR):\n",
    "        shutil.rmtree(RAW_DIR)\n",
    "    shutil.move(str(extracted_root), RAW_DIR)\n",
    "    print(\"Dataset placed at:\", RAW_DIR)\n",
    "    # cleanup zip\n",
    "    os.remove(tmp_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "279803ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_image_files(root):\n",
    "    files = []\n",
    "    classes = []\n",
    "    for cls in sorted(os.listdir(root)):\n",
    "        cls_path = os.path.join(root, cls)\n",
    "        if not os.path.isdir(cls_path):\n",
    "            continue\n",
    "        classes.append(cls)\n",
    "        for fname in os.listdir(cls_path):\n",
    "            if fname.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                files.append((os.path.join(cls_path, fname), cls))\n",
    "    return files, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79661201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_resize(path, size):\n",
    "    # Load image with PIL, convert to RGB, resize with Lanczos for quality\n",
    "    with Image.open(path) as im:\n",
    "        im = im.convert(\"RGB\")\n",
    "        # optional: pad to square then resize (keeps aspect)\n",
    "        im = ImageOps.fit(im, (size, size), Image.LANCZOS)\n",
    "        arr = np.array(im, dtype=np.float32)\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34a1ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample_gallery(images, labels, out_path, ncols=6):\n",
    "    n = len(images)\n",
    "    ncols = min(ncols, n)\n",
    "    nrows = (n + ncols - 1) // ncols\n",
    "    fig, ax = plt.subplots(nrows, ncols, figsize=(ncols*2, nrows*2))\n",
    "    ax = np.array(ax).reshape(-1)\n",
    "    for i in range(len(ax)):\n",
    "        ax[i].axis(\"off\")\n",
    "    for i, (img, lbl) in enumerate(zip(images, labels)):\n",
    "        ax[i].imshow(img.astype(np.uint8))\n",
    "        ax[i].set_title(lbl, fontsize=8)\n",
    "        ax[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.savefig(out_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157de2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_and_save():\n",
    "    # ensure dataset present\n",
    "    ensure_dataset_downloaded()\n",
    "\n",
    "    files, classes = list_image_files(RAW_DIR)\n",
    "    if not files:\n",
    "        raise RuntimeError(\"No image files found in dataset. Check RAW_DIR structure.\")\n",
    "    print(f\"Found {len(files)} images across {len(classes)} classes.\")\n",
    "    random.seed(42)\n",
    "    random.shuffle(files)\n",
    "\n",
    "    # load images into memory\n",
    "    X = []\n",
    "    y = []\n",
    "    for i, (fpath, cls) in enumerate(files):\n",
    "        try:\n",
    "            img = load_and_resize(fpath, IMG_SIZE)\n",
    "            X.append(img)\n",
    "            y.append(cls)\n",
    "        except Exception as e:\n",
    "            print(\"Error loading\", fpath, e)\n",
    "    X = np.stack(X, axis=0)   # shape (N, H, W, 3)\n",
    "    y = np.array(y)\n",
    "    print(\"Loaded array shape:\", X.shape)\n",
    "\n",
    "    # normalize to [0,1]\n",
    "    X = X / 255.0\n",
    "\n",
    "    # integer labels\n",
    "    class_list = sorted(list(set(y)))\n",
    "    cls_to_idx = {c: i for i, c in enumerate(class_list)}\n",
    "    y_int = np.array([cls_to_idx[c] for c in y], dtype=np.int32)\n",
    "\n",
    "    # stratified split: train 70%, then val/test 15% each\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(\n",
    "        X, y_int, train_size=0.70, stratify=y_int, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_rem, y_rem, test_size=0.5, stratify=y_rem, random_state=42)\n",
    "\n",
    "    print(\"Split sizes: train\", X_train.shape[0], \"val\", X_val.shape[0], \"test\", X_test.shape[0])\n",
    "\n",
    "    # one-hot labels\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    num_classes = len(class_list)\n",
    "    y_train_oh = to_categorical(y_train, num_classes)\n",
    "    y_val_oh = to_categorical(y_val, num_classes)\n",
    "    y_test_oh = to_categorical(y_test, num_classes)\n",
    "\n",
    "    # class weights\n",
    "    counts = Counter(y_train)\n",
    "    total = len(y_train)\n",
    "    class_weights = {int(k): float(total / (len(counts) * v)) for k, v in counts.items()}\n",
    "    print(\"Class counts (train):\", counts)\n",
    "    print(\"Class weights:\", class_weights)\n",
    "\n",
    "    # save prepared data\n",
    "    os.makedirs(os.path.dirname(OUT_PREPARED), exist_ok=True)\n",
    "    np.savez_compressed(OUT_PREPARED,\n",
    "                        X_train=X_train, y_train=y_train_oh, y_train_int=y_train,\n",
    "                        X_val=X_val, y_val=y_val_oh, y_val_int=y_val,\n",
    "                        X_test=X_test, y_test=y_test_oh, y_test_int=y_test,\n",
    "                        classes=np.array(class_list), class_weights=class_weights)\n",
    "    print(\"Saved prepared dataset to\", OUT_PREPARED)\n",
    "\n",
    "    # save small sample gallery\n",
    "    sample_idxs = list(range(min(24, X_train.shape[0])))\n",
    "    sample_images = (X_train * 255.0).astype(np.uint8)[sample_idxs]\n",
    "    sample_labels = [class_list[int(y_train[i])] for i in sample_idxs]\n",
    "    save_sample_gallery(sample_images, sample_labels, \"outputs/sample_images.png\")\n",
    "    print(\"Saved sample gallery to outputs/sample_images.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "792195d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4752 images across 9 classes.\n",
      "Loaded array shape: (4752, 128, 128, 3)\n",
      "Split sizes: train 3326 val 713 test 713\n",
      "Class counts (train): Counter({6: 645, 3: 553, 5: 350, 4: 346, 0: 323, 8: 305, 2: 294, 1: 288, 7: 222})\n",
      "Class weights: {5: 1.0558730158730159, 6: 0.5729543496985358, 1: 1.283179012345679, 3: 0.668274060679124, 0: 1.1441348469212247, 7: 1.6646646646646646, 8: 1.2116575591985428, 2: 1.256991685563114, 4: 1.0680796403339756}\n",
      "Saved prepared dataset to ../data/realwaste_prepared.npz\n",
      "Saved sample gallery to outputs/sample_images.png\n",
      "Data preparation complete. Next step: training.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    os.makedirs(\"../outputs\", exist_ok=True)\n",
    "    prepare_and_save()\n",
    "    print(\"Data preparation complete. Next step: training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b94c186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9762471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea95b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17712dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8082ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed3f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e75b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a654a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd0fc39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c299b57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
